# CGNAT_Log

NOTE: ********* this document has not completed yet ********

To collect CGNAT logs and store them in DB to search and find specific data faster.

In this project, Radius servers are used for AAA and Brases as ras. Also, we need some servers to collect logs and parse them into our appropriate data type, human-readable and store them in the clickhouse database.

Our users connect to Bras and Bras sends logs to its sensor called bras_sensor, each Bras has one sensor to collect Bras logs by Rsyslog and parse its logs.

Another sensor called Radius_sensor sniffs Radius traffic and stores logs by Tcpdump, then parse and extracts some specific radius attributes and stores them into radius DB called online user.

finally bras-report.sh collect data from radius.ou(online users) and bras sensor data and store them in the main DB.

For doing this project faster I use PyPy to run python code faster than usual.

How to config:

1- Bras_sensor:

OS: Linux (resource should be considered according to the amount of traffic and logs generated by Bras)
Please configure Bras to send logs by Syslog format to bras_sensor (TCP or UDP port: 514), you need to configure Rsyslog to listen to port 514.

by using cgnat.conf file and copy it to /etc/rsyslog/conf.d/ Rsyslog parse logs(in this case Cisco Nat log format) and store them into /srv/log/cgnat/year.

bras.py will open saved logs and connects to radius DB (online users table) then save the final file into /root/bras/bras-report and Main DB on the database server. (you can have more than one main DB, based on your data size)

crontab runs bras.py.
*/2 * * * * root python3 /root/bras/bras.py &> /dev/null
use these crons to remove old files(you can change time and directories):
2 3 * * * root echo "$(du -sh)" > /root/bras/rsyslog-backup.txt && find /srv/log/cgnat/sent/$(date \+\%Y)/ -ctime +1 -delete
3 2 * * * root echo "$(du -sh)" > /root/bras/report.txt && find /root/bras/bras-report/ -ctime +1 -delete

2- Radius_Sensor:

sniff received radius packets by Tcpdump and store them into /root/radius/pcap.

online-users.py will parse them and store data in Radius online user table and ~/radius/parsed_file.

old pcap will move into /tmp/old-pcap.

everything is scheduled by crontab.
